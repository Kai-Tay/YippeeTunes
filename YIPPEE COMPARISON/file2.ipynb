{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (0) IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from sklearn.cluster import KMeans\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs\n",
    "from kneed import KneeLocator\n",
    "import time\n",
    "import spotipy\n",
    "import pandas as pd\n",
    "\n",
    "#BORROWING KAISHENGS CLIENT SECRET AND ID THANKS KS BB PLS DONT DISABLE YA\n",
    "auth_manager = SpotifyClientCredentials(client_id=\"21ff73a9b5a94ea8b3a969b906baead1\", client_secret=\"3761e7947ef542149467196a07cf2563\")\n",
    "sp = spotipy.Spotify(auth_manager=auth_manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) FUNCTIONS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ohe_prep(df, column, new_name): \n",
    "    ''' \n",
    "    Create One Hot Encoded features of a specific column\n",
    "    ---\n",
    "    Input: \n",
    "    df (pandas dataframe): Spotify Dataframe\n",
    "    column (str): Column to be processed\n",
    "    new_name (str): new column name to be used\n",
    "        \n",
    "    Output: \n",
    "    tf_df: One-hot encoded features \n",
    "    '''\n",
    "    \n",
    "    tf_df = pd.get_dummies(df[column])\n",
    "    \n",
    "    feature_names = tf_df.columns\n",
    "    tf_df.columns = [new_name + \"|\" + str(i) for i in feature_names]\n",
    "    tf_df.reset_index(drop = True, inplace = True)  \n",
    "    return tf_df\n",
    "\n",
    "def get_features_database(databaseDF, feature_weights):\n",
    "    #Select Features\n",
    "    databaseDF = databaseDF[[\"id\",\"songName\",\n",
    "                \"danceability\",\"energy\",\"key\",\"loudness\",\"mode\",\"speechiness\",\"acousticness\",\"instrumental\",\"liveness\",\n",
    "                \"valence\",\"tempo\",\"type\"]]\n",
    "\n",
    "    #OHE Features\n",
    "    key_ohe = ohe_prep(databaseDF, 'key','key') * feature_weights['key']\n",
    "    mode_ohe = ohe_prep(databaseDF, 'mode','mode') * feature_weights['mode']\n",
    "\n",
    "    ##Normalise/Scale Audio Columns\n",
    "    float_cols = databaseDF.dtypes[databaseDF.dtypes == 'float64'].index.values\n",
    "    floats = databaseDF[float_cols].reset_index(drop = True)\n",
    "    scaler = MinMaxScaler()\n",
    "    floats_scaled = pd.DataFrame(scaler.fit_transform(floats), columns = floats.columns)\n",
    "\n",
    "    # Apply weight to each float column\n",
    "    for col in floats_scaled.columns:\n",
    "        floats_scaled[col] *= feature_weights.get(col, 1.0)\n",
    "\n",
    "    ##Combine all Features\n",
    "    final = pd.concat([floats_scaled, key_ohe, mode_ohe, databaseDF[\"type\"]], axis = 1)\n",
    "    return final\n",
    "\n",
    "\n",
    "feature_weight = {\n",
    "    \"danceability\": 0.6,\n",
    "    \"energy\": 0.7,\n",
    "    \"key\": 0.1,\n",
    "    \"loudness\": 0.8,\n",
    "    \"mode\": 0.1,\n",
    "    \"speechiness\": 0.5,\n",
    "    \"acousticness\": 0.3,\n",
    "    \"instrumentalness\": 0.5,\n",
    "    \"liveness\": 0.3,\n",
    "    \"valence\": 0.7,\n",
    "    \"tempo\": 0.6,\n",
    "    \"type\": 0.1\n",
    "}\n",
    "\n",
    "def generate_rec(databaseDF, database_vector, user_vector):\n",
    "    #Cosine Similarity\n",
    "    databaseDF[\"sim\"] = cosine_similarity(database_vector,user_vector)\n",
    "    \n",
    "    #Remove sim = 1 as it means its the same song\n",
    "    databaseDF.drop(databaseDF[databaseDF['sim'] >= 1].index, inplace = True)\n",
    "\n",
    "    rec_top5 = databaseDF.sort_values('sim',ascending = False).head(5)\n",
    "    return rec_top5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only weightage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>songName</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumental</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>390972</th>\n",
       "      <td>2mc3zZV0zf7PBLS6j8pspA</td>\n",
       "      <td>Hooker</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.896</td>\n",
       "      <td>5</td>\n",
       "      <td>-2.478</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1790</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.442</td>\n",
       "      <td>146.275</td>\n",
       "      <td>0.993219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187931</th>\n",
       "      <td>7MtpXnAhLKdkXjoFaK95TB</td>\n",
       "      <td>katharsis</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.828</td>\n",
       "      <td>8</td>\n",
       "      <td>-3.193</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.0397</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.391</td>\n",
       "      <td>144.276</td>\n",
       "      <td>0.992397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154201</th>\n",
       "      <td>3kQQdvJufvdRkXlz8PZWjP</td>\n",
       "      <td>Calm Down</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.930</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.121</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.0385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.462</td>\n",
       "      <td>151.996</td>\n",
       "      <td>0.992341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496599</th>\n",
       "      <td>6l7EaSqG6hIBBztg8xi1Xm</td>\n",
       "      <td>The P.A.S.E.O. (The Poem Aaron Saw Extra Ordin...</td>\n",
       "      <td>0.619</td>\n",
       "      <td>0.831</td>\n",
       "      <td>11</td>\n",
       "      <td>-3.836</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0772</td>\n",
       "      <td>0.0715</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.392</td>\n",
       "      <td>148.342</td>\n",
       "      <td>0.992332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89895</th>\n",
       "      <td>2mQ7KmAI8gFLH3baaDXc6o</td>\n",
       "      <td>How Deep Is Your Love - DJ Snake Remix</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0.903</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.475</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0938</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.001020</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.446</td>\n",
       "      <td>149.930</td>\n",
       "      <td>0.992305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            id  \\\n",
       "390972  2mc3zZV0zf7PBLS6j8pspA   \n",
       "187931  7MtpXnAhLKdkXjoFaK95TB   \n",
       "154201  3kQQdvJufvdRkXlz8PZWjP   \n",
       "496599  6l7EaSqG6hIBBztg8xi1Xm   \n",
       "89895   2mQ7KmAI8gFLH3baaDXc6o   \n",
       "\n",
       "                                                 songName  danceability  \\\n",
       "390972                                             Hooker         0.604   \n",
       "187931                                          katharsis         0.555   \n",
       "154201                                          Calm Down         0.595   \n",
       "496599  The P.A.S.E.O. (The Poem Aaron Saw Extra Ordin...         0.619   \n",
       "89895              How Deep Is Your Love - DJ Snake Remix         0.616   \n",
       "\n",
       "        energy  key  loudness  mode  speechiness  acousticness  instrumental  \\\n",
       "390972   0.896    5    -2.478     1       0.1790        0.0464      0.000004   \n",
       "187931   0.828    8    -3.193     1       0.1500        0.0397      0.000000   \n",
       "154201   0.930    1    -2.121     1       0.0990        0.0385      0.000000   \n",
       "496599   0.831   11    -3.836     1       0.0772        0.0715      0.000000   \n",
       "89895    0.903    9    -0.475     1       0.0938        0.0150      0.001020   \n",
       "\n",
       "        liveness  valence    tempo       sim  \n",
       "390972     0.190    0.442  146.275  0.993219  \n",
       "187931     0.163    0.391  144.276  0.992397  \n",
       "154201     0.253    0.462  151.996  0.992341  \n",
       "496599     0.179    0.392  148.342  0.992332  \n",
       "89895      0.141    0.446  149.930  0.992305  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extract Database CSV\n",
    "databaseDF = pd.read_csv(\"spotify_dataset_eda.csv\", encoding=\"utf_8_sig\")\n",
    "databaseDF = databaseDF.drop(columns=['Unnamed: 0'])\n",
    "#Selects columns that we want\n",
    "databaseDF = databaseDF[[\"id\",\"songName\",\n",
    "        \"danceability\",\"energy\",\"key\",\"loudness\",\"mode\",\"speechiness\",\"acousticness\",\"instrumental\",\"liveness\",\n",
    "        \"valence\",\"tempo\",]]\n",
    "\n",
    "\n",
    "#Extract User Playlist CSV\n",
    "playlistDF = pd.read_csv(\"User_Playlist.csv\", encoding=\"utf_8_sig\")\n",
    "playlistDF = playlistDF.drop(columns=['Unnamed: 0'])\n",
    "#Reset Index\n",
    "playlistDF = playlistDF.reset_index(drop = True)  \n",
    "#Selects columns that we want\n",
    "playlistDF = playlistDF[[\"id\",\"songName\",\n",
    "        \"danceability\",\"energy\",\"key\",\"loudness\",\"mode\",\"speechiness\",\"acousticness\",\"instrumental\",\"liveness\",\n",
    "        \"valence\",\"tempo\",]] \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Merge user + dataset dataframe to normalise \n",
    "#Normalise takes min and max in dataframe as reference and change it to 0 and 1 respectively\n",
    "\n",
    "#Group the dataframe as we gonna split it again alter\n",
    "databaseDF[\"type\"] = \"Dataset\"\n",
    "playlistDF[\"type\"] = \"User\"\n",
    "\n",
    "\n",
    "#Check for duplicates in database\n",
    "databaseDF = databaseDF.drop_duplicates(ignore_index= True)\n",
    "\n",
    "#Merge the 2 datasets together\n",
    "combinedDF = pd.concat([databaseDF,playlistDF], ignore_index=True)\n",
    "\n",
    "\n",
    "##Normalise and get Vectors for Dataset + User\n",
    "normalised_vector = get_features_database(combinedDF,feature_weight)\n",
    "\n",
    "##Seperate User from databaseDF \n",
    "database_vector = normalised_vector[normalised_vector[\"type\"] == \"Dataset\"]\n",
    "user_vector = normalised_vector[normalised_vector[\"type\"] == \"User\"]\n",
    "\n",
    "#Drop \"type\" column\n",
    "database_vector = database_vector.drop(columns=\"type\")\n",
    "user_vector = user_vector.drop(columns=\"type\")\n",
    "databaseDF = databaseDF.drop(columns=[\"type\"])\n",
    "\n",
    "\n",
    "##Single Vector Creation\n",
    "final_user_vector_list = []\n",
    "for i in user_vector.columns:\n",
    "    final_user_vector_list.append(user_vector[i].sum()/len(user_vector[i]))\n",
    "\n",
    "#Putting into a vector dataframe\n",
    "final_user_vector = pd.DataFrame(columns=user_vector.columns,)\n",
    "final_user_vector.loc[0] = final_user_vector_list\n",
    "\n",
    "##Generate Recc Songs\n",
    "result = generate_rec(databaseDF,database_vector,final_user_vector)\n",
    "result\n",
    "\n",
    "result['id'] = result['id'].apply(lambda x: 'https://open.spotify.com/track/' + str(x))\n",
    "# Convert the 'id' column to HTML hyperlinks\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weightage + Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cache folder (C:\\Users\\jiowe\\.cache\\selenium) cannot be created: Cannot create a file when that file already exists. (os error 183)\n",
      "Cache folder (C:\\Users\\jiowe\\.cache\\selenium) cannot be created: Cannot create a file when that file already exists. (os error 183)\n",
      "Cache folder (C:\\Users\\jiowe\\.cache\\selenium) cannot be created: Cannot create a file when that file already exists. (os error 183)\n",
      "Cache folder (C:\\Users\\jiowe\\.cache\\selenium) cannot be created: Cannot create a file when that file already exists. (os error 183)\n",
      "Cache folder (C:\\Users\\jiowe\\.cache\\selenium) cannot be created: Cannot create a file when that file already exists. (os error 183)\n",
      "Cache folder (C:\\Users\\jiowe\\.cache\\selenium) cannot be created: Cannot create a file when that file already exists. (os error 183)\n",
      "Cache folder (C:\\Users\\jiowe\\.cache\\selenium) cannot be created: Cannot create a file when that file already exists. (os error 183)\n",
      "Cache folder (C:\\Users\\jiowe\\.cache\\selenium) cannot be created: Cannot create a file when that file already exists. (os error 183)\n",
      "Cache folder (C:\\Users\\jiowe\\.cache\\selenium) cannot be created: Cannot create a file when that file already exists. (os error 183)\n",
      "Cache folder (C:\\Users\\jiowe\\.cache\\selenium) cannot be created: Cannot create a file when that file already exists. (os error 183)\n",
      "Cache folder (C:\\Users\\jiowe\\.cache\\selenium) cannot be created: Cannot create a file when that file already exists. (os error 183)\n",
      "Cache folder (C:\\Users\\jiowe\\.cache\\selenium) cannot be created: Cannot create a file when that file already exists. (os error 183)\n",
      "Cache folder (C:\\Users\\jiowe\\.cache\\selenium) cannot be created: Cannot create a file when that file already exists. (os error 183)\n",
      "Cache folder (C:\\Users\\jiowe\\.cache\\selenium) cannot be created: Cannot create a file when that file already exists. (os error 183)\n",
      "Cache folder (C:\\Users\\jiowe\\.cache\\selenium) cannot be created: Cannot create a file when that file already exists. (os error 183)\n",
      "Cache folder (C:\\Users\\jiowe\\.cache\\selenium) cannot be created: Cannot create a file when that file already exists. (os error 183)\n",
      "Cache folder (C:\\Users\\jiowe\\.cache\\selenium) cannot be created: Cannot create a file when that file already exists. (os error 183)\n",
      "Cache folder (C:\\Users\\jiowe\\.cache\\selenium) cannot be created: Cannot create a file when that file already exists. (os error 183)\n",
      "Cache folder (C:\\Users\\jiowe\\.cache\\selenium) cannot be created: Cannot create a file when that file already exists. (os error 183)\n",
      "Cache folder (C:\\Users\\jiowe\\.cache\\selenium) cannot be created: Cannot create a file when that file already exists. (os error 183)\n",
      "Cache folder (C:\\Users\\jiowe\\.cache\\selenium) cannot be created: Cannot create a file when that file already exists. (os error 183)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 Genre's of User Playlist:['metal', 'country', 'hip hop']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>artist</th>\n",
       "      <th>songName</th>\n",
       "      <th>genre</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumental</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>artist_songName</th>\n",
       "      <th>sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60273</th>\n",
       "      <td>7aftSOGSOpSoIlVAQVBb71</td>\n",
       "      <td>Sam Hunt</td>\n",
       "      <td>Break Up In A Small Town</td>\n",
       "      <td>country</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.776</td>\n",
       "      <td>8</td>\n",
       "      <td>-5.365</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1730</td>\n",
       "      <td>0.074900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.434</td>\n",
       "      <td>136.044</td>\n",
       "      <td>sam hunt_break up in a small town</td>\n",
       "      <td>0.991965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279842</th>\n",
       "      <td>4B0nJLbPzVxWt7o99SiGrO</td>\n",
       "      <td>Tyler Hubbard</td>\n",
       "      <td>35’s</td>\n",
       "      <td>country</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.790</td>\n",
       "      <td>10</td>\n",
       "      <td>-5.698</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0553</td>\n",
       "      <td>0.003580</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.402</td>\n",
       "      <td>139.929</td>\n",
       "      <td>tyler hubbard_35’s</td>\n",
       "      <td>0.991776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287845</th>\n",
       "      <td>03Mfd5obNNFGKWKBWP1B9t</td>\n",
       "      <td>GHOST DATA</td>\n",
       "      <td>Adagio For Souls</td>\n",
       "      <td>hip hop</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.748</td>\n",
       "      <td>5</td>\n",
       "      <td>-5.112</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0942</td>\n",
       "      <td>0.086300</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.389</td>\n",
       "      <td>145.077</td>\n",
       "      <td>ghost data_adagio for souls</td>\n",
       "      <td>0.991731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448560</th>\n",
       "      <td>2QXO5ceopNHeYUyRTp78Wy</td>\n",
       "      <td>.sPout.</td>\n",
       "      <td>Take Me (Take Me)</td>\n",
       "      <td>metal</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.347</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1330</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.416</td>\n",
       "      <td>139.975</td>\n",
       "      <td>.spout._take me (take me)</td>\n",
       "      <td>0.991686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390244</th>\n",
       "      <td>17U4zkPHe30IUnikRdJu2L</td>\n",
       "      <td>Sepultura</td>\n",
       "      <td>The Waste (with Mike Patton)</td>\n",
       "      <td>metal</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.824</td>\n",
       "      <td>10</td>\n",
       "      <td>-6.067</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0662</td>\n",
       "      <td>0.000687</td>\n",
       "      <td>0.051700</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.421</td>\n",
       "      <td>133.399</td>\n",
       "      <td>sepultura_the waste (with mike patton)</td>\n",
       "      <td>0.991553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            id         artist                      songName  \\\n",
       "60273   7aftSOGSOpSoIlVAQVBb71       Sam Hunt      Break Up In A Small Town   \n",
       "279842  4B0nJLbPzVxWt7o99SiGrO  Tyler Hubbard                          35’s   \n",
       "287845  03Mfd5obNNFGKWKBWP1B9t     GHOST DATA              Adagio For Souls   \n",
       "448560  2QXO5ceopNHeYUyRTp78Wy        .sPout.             Take Me (Take Me)   \n",
       "390244  17U4zkPHe30IUnikRdJu2L      Sepultura  The Waste (with Mike Patton)   \n",
       "\n",
       "          genre  danceability  energy  key  loudness  mode  speechiness  \\\n",
       "60273   country         0.579   0.776    8    -5.365     1       0.1730   \n",
       "279842  country         0.535   0.790   10    -5.698     1       0.0553   \n",
       "287845  hip hop         0.501   0.748    5    -5.112     1       0.0942   \n",
       "448560    metal         0.583   0.786    0    -4.347     1       0.1330   \n",
       "390244    metal         0.603   0.824   10    -6.067     1       0.0662   \n",
       "\n",
       "        acousticness  instrumental  liveness  valence    tempo  \\\n",
       "60273       0.074900      0.000000     0.239    0.434  136.044   \n",
       "279842      0.003580      0.000000     0.257    0.402  139.929   \n",
       "287845      0.086300      0.000152     0.181    0.389  145.077   \n",
       "448560      0.001890      0.000019     0.130    0.416  139.975   \n",
       "390244      0.000687      0.051700     0.153    0.421  133.399   \n",
       "\n",
       "                               artist_songName       sim  \n",
       "60273        sam hunt_break up in a small town  0.991965  \n",
       "279842                      tyler hubbard_35’s  0.991776  \n",
       "287845             ghost data_adagio for souls  0.991731  \n",
       "448560               .spout._take me (take me)  0.991686  \n",
       "390244  sepultura_the waste (with mike patton)  0.991553  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_rec(databaseDF, database_vector, user_vector, genre_top3, useSpotifyGenre):\n",
    "    #Cosine Similarity\n",
    "    databaseDF[\"sim\"] = cosine_similarity(database_vector,user_vector)\n",
    "\n",
    "    #Drop rows with different genre from top 3 genres\n",
    "    if len(genre_top3) == 1:\n",
    "        databaseDF = databaseDF[(databaseDF[\"genre\"] == genre_top3[0])]\n",
    "    elif len(genre_top3) == 2:\n",
    "        databaseDF = databaseDF[(databaseDF[\"genre\"] == genre_top3[0]) | (databaseDF[\"genre\"] == genre_top3[1])]\n",
    "    else:\n",
    "        databaseDF = databaseDF[(databaseDF[\"genre\"] == genre_top3[0]) | (databaseDF[\"genre\"] == genre_top3[1]) | (databaseDF[\"genre\"] == genre_top3[2])]\n",
    "    #Sort and recommend top 5 with same genres\n",
    "    rec_top5 = databaseDF.sort_values('sim',ascending = False).head()\n",
    "    return rec_top5\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "\n",
    "\n",
    "\n",
    "##GENRE ENGINEERING\n",
    "genre_dict = {\n",
    "    \"pop\": [\"pop punk\", \"pop rap\", \"pop rock\", \"synthpop\",\"dance-pop\", \"singer-songwriter\"],\n",
    "    \"rock\": [\"psych rock\",\"power pop\",\"alt rock\", \"hard rock\",\"emo\",\"blues\", \"folk\", \"garage\", \"pop rock\", \"acoustic\", \"rock and roll\", \"singer-songwriter\", \"\"],\n",
    "    \"metal\": [\"metalcore\",\"black metal\", \"death metal\", \"heavy metal\", \"goth\", \"gothic metal\", \"groove\", \"punk\", \"grindcore\", \"industrial\", \"alternative metal\"],\n",
    "    \"house\": [\"chicago house\", \"progressive house\", \"deep house\", \"edm\", \"electro house\", \"future house\", \"tech house\"],\n",
    "    \"country\": [\"country pop\", \"country blues\", \"country rap\", \"country rock\"],\n",
    "    \"r&b\": [\"soul\",\"dance\",\"contemporary r&b\", \"alternative r&b\", \"soul jazz\", \"r&b and soul\",\"rhythm and blues\"],\n",
    "    \"techno\": [\"detroit techno\",\"minimal techno\", \"hardcore\"],\n",
    "    \"electro\": [\"drum and bass\",\"dubstep\",\"electronic\", \"club\", \"electro house\", \"electronic dance music\", \"electro swing\", \"electropop\"],\n",
    "    \"hip hop\": [\"rap\", \"funk\", \"alternative hip hop\", \"rap rock\", \"rap metal\", \"jazz rap\"],\n",
    "    \"k-pop\": [],\n",
    "    \"indie\": [\"indie rock\", \"indie pop\"]\n",
    "}\n",
    "\n",
    "def generaliseGenre(genre):\n",
    "    for key,value in genre_dict.items():\n",
    "        ##if genre scrapped is same as generic genre(key), return genre\n",
    "        if key == genre:\n",
    "            return key\n",
    "        else:\n",
    "            ##iterate through all the genres (value) in the dict to find suitable generic genre\n",
    "            for alt_genre in value:\n",
    "                if alt_genre == genre:\n",
    "                    return key\n",
    "    ##return none if no genre found\n",
    "    return None\n",
    "\n",
    "def scrap_genre(artistName):\n",
    "    ##URL of website to scrap\n",
    "    url = f\"https://www.getgenre.com/artist/{artistName}\"\n",
    "\n",
    "\n",
    "    ##CHANGE PATH TO PATH OF DOWNLOADED CHROMEDRIVER\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--headless')\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "    options.add_argument('--disable-gpu')\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    \n",
    "    # WAIT FOR BUTTON TAG TO LOAD BEFORE CONTINUING\n",
    "    driver.implicitly_wait(20)\n",
    "    driver.get(url)\n",
    "    \n",
    "    try:\n",
    "        classtext = \"MuiButtonBase-root MuiButton-root MuiButton-outlined MuiButton-outlinedPrimary MuiButton-sizeMedium MuiButton-outlinedSizeMedium MuiButton-root MuiButton-outlined MuiButton-outlinedPrimary MuiButton-sizeMedium MuiButton-outlinedSizeMedium css-x3ahaf\"\n",
    "        button = driver.find_element(By.XPATH, '//*[@id=\"genres-text\"]/div/button')\n",
    "        time.sleep(5)\n",
    "        # Parse the HTML content of the button with BS4\n",
    "        html = button.get_attribute(\"outerHTML\")\n",
    "        driver.close()\n",
    "        driver.quit()\n",
    "\n",
    "        #Use BS4 to read HTML segement and extract Genre Text\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "        # Find html button tag with class to obtained genre text\n",
    "        genre = soup.find('button', class_=classtext).get_text().lower()\n",
    "        result = generaliseGenre(genre)\n",
    "        return result\n",
    "    except:\n",
    "        driver.close()\n",
    "        driver.quit()\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##Import User Playlist\n",
    "userDF = pd.read_csv(\"User_Playlist.csv\")\n",
    "userDF = userDF.drop(columns=[\"Unnamed: 0\"])\n",
    "##Import Dataset\n",
    "df = pd.read_csv(\"spotify_dataset_eda.csv\")\n",
    "df = df.drop(columns=[\"Unnamed: 0\"])\n",
    "df = df.dropna()\n",
    "\n",
    "#Extract all genres from dataset\n",
    "datasetGenres_list = []\n",
    "for i in df[\"genre\"]:\n",
    "    if i not in datasetGenres_list:\n",
    "        datasetGenres_list.append(i)\n",
    "\n",
    "# Flag to indicate whether need to use Method 3 or not\n",
    "useSpotifyGenre = False\n",
    "\n",
    "song_genres_list = []\n",
    "##Find Playlist Songs in Database and replace genre\n",
    "\n",
    "for index, row in userDF.iterrows():\n",
    "    id = row[\"id\"]\n",
    "    artistName = row[\"artist\"]\n",
    "\n",
    "    ##List to include all genres from one song\n",
    "    one_song_genre = []\n",
    "\n",
    "    ##variable to check if song in database\n",
    "    dataset_genre = df[df[\"id\"] == id]\n",
    "\n",
    "    if not dataset_genre.empty:\n",
    "        ##METHOD1 - Copying Dataset genre to User Dataset\n",
    "        one_song_genre = dataset_genre[\"genre\"].to_list()\n",
    "    else:\n",
    "        ##METHOD2 - Web Scraping\n",
    "        genre = scrap_genre(artistName)\n",
    "        if genre != \"\":\n",
    "            one_song_genre.append(genre)\n",
    "\n",
    "    ##CHECKS IF METHOD 1/2 managed to obtain genre data\n",
    "    song_genres_list.append(one_song_genre)\n",
    "\n",
    "userDF[\"genre\"] = song_genres_list\n",
    "userDF\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# (2) Find top 3 genres in playlist\n",
    "exploded_df = userDF.explode('genre')\n",
    "\n",
    "freq = exploded_df[\"genre\"].value_counts(sort=True)\n",
    "\n",
    "genres_count = dict(freq.head(3))\n",
    "genre_top3 = list(genres_count.keys())\n",
    "        \n",
    "print(\"Top 3 Genre's of User Playlist:\" + str(genre_top3))\n",
    "exploded_df\n",
    "\n",
    "\n",
    "#Extract Database CSV\n",
    "databaseDF = pd.read_csv(\"spotify_dataset_eda.csv\", encoding=\"utf_8_sig\")\n",
    "databaseDF = databaseDF.drop(columns=['Unnamed: 0'])\n",
    "#Selects columns that we want\n",
    "databaseDF = databaseDF[[\"id\",\"artist\",\"songName\", \"genre\",\"danceability\",\"energy\",\"key\",\"loudness\",\"mode\",\"speechiness\",\"acousticness\",\"instrumental\",\"liveness\",\n",
    "        \"valence\",\"tempo\",]]\n",
    "\n",
    "#Create new feature/column of artist_songName\n",
    "databaseDF[\"artist_songName\"] = databaseDF[\"artist\"] + \"_\" + databaseDF[\"songName\"]\n",
    "\n",
    "##Change all values to lowercase\n",
    "databaseDF[\"artist_songName\"] = databaseDF[\"artist_songName\"].str.lower()\n",
    "\n",
    "#Check for duplicates in database\n",
    "databaseDF = databaseDF.drop_duplicates(subset=[\"artist_songName\"],ignore_index= True)\n",
    "\n",
    "\n",
    "\n",
    "#Extract User Playlist CSV\n",
    "playlistDF = pd.read_csv(\"User_Playlist.csv\", encoding=\"utf_8_sig\")\n",
    "\n",
    "playlistDF = playlistDF.drop(columns=['Unnamed: 0'])\n",
    "#Reset Index\n",
    "playlistDF = playlistDF.reset_index(drop = True)  \n",
    "#Selects columns that we want\n",
    "playlistDF = playlistDF[[\"id\",\"artist\",\"songName\",\"danceability\",\"energy\",\"key\",\"loudness\",\"mode\",\"speechiness\",\"acousticness\",\"instrumental\",\"liveness\",\n",
    "        \"valence\",\"tempo\",]] \n",
    "\n",
    "#Create new feature/column of artist_songName to remove duplicate later on\n",
    "playlistDF[\"artist_songName\"] = playlistDF[\"artist\"] + \"_\" + playlistDF[\"songName\"]\n",
    "##Change all values to lowercase\n",
    "playlistDF[\"artist_songName\"] = playlistDF[\"artist_songName\"].str.lower()\n",
    "\n",
    "#Check for duplicates in user Playlist\n",
    "playlistDF = playlistDF.drop_duplicates(subset=[\"artist_songName\"],ignore_index= True)\n",
    "\n",
    "\n",
    "#Merge user + dataset dataframe to normalise \n",
    "#Normalise takes min and max in dataframe as reference and change it to 0 and 1 respectively\n",
    "\n",
    "#Group the dataframe as we gonna split it again alter\n",
    "databaseDF[\"type\"] = \"Dataset\"\n",
    "playlistDF[\"type\"] = \"User\"\n",
    "\n",
    "\n",
    "#Merge the 2 datasets together\n",
    "combinedDF = pd.concat([databaseDF,playlistDF], ignore_index=True)\n",
    "\n",
    "#Check for duplicates between user and Database\n",
    "combinedDF = combinedDF.drop_duplicates(subset=[\"artist_songName\"], keep=\"last\",ignore_index= True)\n",
    "\n",
    "##Update databaseDF with removed songs from user Playlist\n",
    "databaseDF = combinedDF[(combinedDF[\"type\"]== \"Dataset\")]\n",
    "\n",
    "##Normalise and get Vectors for Dataset + User\n",
    "normalised_vector = get_features_database(combinedDF,feature_weight)\n",
    "\n",
    "##Seperate User from databaseDF \n",
    "database_vector = normalised_vector[normalised_vector[\"type\"] == \"Dataset\"]\n",
    "user_vector = normalised_vector[normalised_vector[\"type\"] == \"User\"]\n",
    "\n",
    "#Drop \"type\" column\n",
    "database_vector = database_vector.drop(columns=\"type\")\n",
    "user_vector = user_vector.drop(columns=\"type\")\n",
    "databaseDF = databaseDF.drop(columns=[\"type\"])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##Single Vector Creation\n",
    "final_user_vector_list = []\n",
    "for i in user_vector.columns:\n",
    "    final_user_vector_list.append(user_vector[i].sum()/len(user_vector[i]))\n",
    "\n",
    "#Putting into a vector dataframe\n",
    "final_user_vector = pd.DataFrame(columns=user_vector.columns,)\n",
    "final_user_vector.loc[0] = final_user_vector_list\n",
    "\n",
    "\n",
    "##Generate Recc Songs\n",
    "result = generate_rec(databaseDF,database_vector,final_user_vector, genre_top3, useSpotifyGenre)\n",
    "result\n",
    "\n",
    "result['id'] = result['id'].apply(lambda x: 'https://open.spotify.com/track/' + str(x))\n",
    "# Convert the 'id' column to HTML hyperlinks\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spotify",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
